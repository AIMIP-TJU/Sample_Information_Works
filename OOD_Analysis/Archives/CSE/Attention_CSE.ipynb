{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorwatch as tw\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from utils.dataset import *\n",
    "import torch.utils.data as data\n",
    "\n",
    "from utils.train import *\n",
    "from utils.test  import *\n",
    "from vit_rollout import VITAttentionRollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "####### test作训练集 #######\n",
    "# epochs = 80\n",
    "# lr = 3e-6\n",
    "# gamma = 0.7\n",
    "# step_size = 5\n",
    "###### train作训练集 #######\n",
    "epochs = 20\n",
    "lr = 3e-5\n",
    "gamma = 0.8\n",
    "step_size = 5\n",
    "\n",
    "seed = 42\n",
    "device = 'cuda:1'\n",
    "\n",
    "file_Path = '/home/a611/Projects/Datasets/CSE_v1/images/'\n",
    "train_name = ['/home/a611/Projects/Datasets/CSE_v1/labels/train_aver_75.csv']\n",
    "test_name = ['/home/a611/Projects/Datasets/CSE_v1/labels/train_aver_25.csv']\n",
    "num_classes = 11\n",
    "num_input = 3\n",
    "batch_size = 16\n",
    "num_workers = 8\n",
    "########################\n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask_on_image(img, mask):\n",
    "    img = np.float32(img) / 255\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/a611/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('log') #建立一个保存数据用的东西\n",
    "model = torch.hub.load('facebookresearch/deit:main', \n",
    "    'deit_tiny_patch16_224', pretrained=False)\n",
    "model.head = nn.Linear(in_features = model.head.in_features, out_features = num_classes, bias = True)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEIyZaYXRkZF"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YKR5RaykR58x"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0JAXWWtSXpB"
   },
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pC-D9a8xSZNd"
   },
   "outputs": [],
   "source": [
    "label_map = get_map(test_name)\n",
    "label_key = list(label_map.keys())\n",
    "train_set = MyDataset(file_Path, train_name, label_map,\n",
    "                            train_transforms)\n",
    "train_loader = data.DataLoader(\n",
    "    dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "valid_set = MyDataset(file_Path, test_name, label_map,\n",
    "                            val_transforms)\n",
    "valid_loader = data.DataLoader(\n",
    "    dataset=valid_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JiIcaG1zSZLA",
    "outputId": "bd4d6e91-6c28-4b42-f242-246250dc55f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(valid_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF9yMaRrSvmv"
   },
   "source": [
    "## Effecient Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4u5YZG1eozIv"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 001, train_loss: 1.078187, train_acc: 0.599304, test_loss: 0.359867, test_acc: 0.892137\n",
      "Highest test accuracy: 0.892137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 002, train_loss: 0.128822, train_acc: 0.960390, test_loss: 0.072282, test_acc: 0.978965\n",
      "Highest test accuracy: 0.978965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 003, train_loss: 0.052340, train_acc: 0.983505, test_loss: 0.037363, test_acc: 0.991532\n",
      "Highest test accuracy: 0.991532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 004, train_loss: 0.026039, train_acc: 0.993268, test_loss: 0.090712, test_acc: 0.979167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 005, train_loss: 0.026961, train_acc: 0.993716, test_loss: 0.004210, test_acc: 1.000000\n",
      "Highest test accuracy: 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 006, train_loss: 0.008207, train_acc: 0.998205, test_loss: 0.003884, test_acc: 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2599bc3ac07d407eb4e63818165c86b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m test_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(valid_loader)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m test(model, device, test_iter, valid_set, batch_size)\n\u001b[1;32m     10\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Projects/gyc/Local_Features/utils/train.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, dataiter, optimizer, train_set, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m aacc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 针对损失函数的后向传播\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 反向传播后的梯度下降\u001b[39;00m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# 清除旧的梯度信息\u001b[39;00m\n\u001b[1;32m     48\u001b[0m aloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/ViT/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ViT/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ViT/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ViT/lib/python3.9/site-packages/torch/optim/adam.py:133\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.conda/envs/ViT/lib/python3.9/site-packages/torch/optim/_functional.py:86\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m     87\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ = None\n",
    "highest_test_acc = 0\n",
    "for i in range(epochs):\n",
    "    # print('EPOCH:', i + 1)\n",
    "    train_iter = iter(train_loader)\n",
    "    test_iter = iter(valid_loader)\n",
    "    ########################################\n",
    "    train_loss, train_acc = train(model, device, train_iter, optimizer, train_set, batch_size)\n",
    "    test_loss, test_acc = test(model, device, test_iter, valid_set, batch_size)\n",
    "    scheduler.step()\n",
    "    print( 'EPOCH: %03d, train_loss: %3f, train_acc: %3f, test_loss: %3f, test_acc: %3f'\n",
    "          % (i + 1, train_loss, train_acc, test_loss, test_acc))\n",
    "    if test_acc > highest_test_acc:\n",
    "        highest_test_acc = test_acc\n",
    "        model_ = copy.deepcopy(model)\n",
    "        print('Highest test accuracy: %3f' % highest_test_acc)\n",
    "        torch.save(model_, '../models/CSE_train.model')\n",
    "#     print( 'EPOCH: %03d, train_loss: %3f, train_acc: %3f' % (i + 1, train_loss, train_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(x, output, input_type):\n",
    "    output_max = output.argmax(dim=1)\n",
    "    output_numpy = output.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    y = output_numpy[0]\n",
    "    ax.bar(x = x, height = y)\n",
    "    ax.set_title('Item: %s.' % x[int(output_max)], fontsize=15);\n",
    "    xticks = ax.get_xticks()\n",
    "    for i in range(len(y)):\n",
    "        xy = (xticks[i], y[i])\n",
    "        s = '%03f' % y[i]\n",
    "        ax.annotate(\n",
    "            text=s,  # 要添加的文本\n",
    "            xy=xy,  # 将文本添加到哪个位置\n",
    "            fontsize=8,  # 标签大小\n",
    "            color=\"red\",  # 标签颜色\n",
    "            ha=\"center\",  # 水平对齐\n",
    "            va=\"baseline\"  # 垂直对齐\n",
    "        )\n",
    "        plt.savefig(\"../results_%s.jpg\" % input_type)\n",
    "    return output_max\n",
    "\n",
    "def result(x, output, input_type):\n",
    "    output_max = output.argmax(dim=1)\n",
    "    print('Input: %s; Item: %s.' % (input_type, x[int(output_max)]))\n",
    "    return output_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "discard_ratio = 0.9\n",
    "head_fusion = 'max'\n",
    "\n",
    "#########################################\n",
    "# for input_file_name in os.listdir('inputs'):\n",
    "input_file_name = 'building_1.jpg'\n",
    "image_name = os.path.join('inputs',input_file_name)\n",
    "image = Image.open(image_name)\n",
    "img = image.resize((224, 224))\n",
    "input = test_transforms(image).unsqueeze(0)\n",
    "input = input.to(device)\n",
    "output = model(input)\n",
    "# output_max = draw(label_key, output)\n",
    "output_max = result(label_key, output, 'origin')\n",
    "output_max = draw(label_key, output, 'origin')\n",
    "\n",
    "# How to fuse the attention heads for attention rollout. Can be mean/max/min.\n",
    "attention_rollout = VITAttentionRollout(model, head_fusion = head_fusion, discard_ratio = discard_ratio)\n",
    "mask = attention_rollout(input)\n",
    "# name = \"outputs/{}_{}_A-R_{:.3f}_{}.png\".format(input_file_name.split('.')[0], label_key[int(output_max)], discard_ratio, head_fusion)\n",
    "output_name = \"outputs/CSE_test/{}-{}.png\".format(input_file_name.split('.')[0], label_key[int(output_max)])\n",
    "heatmap_name = \"heatmaps/CSE_test/{}-{}.png\".format(input_file_name.split('.')[0], label_key[int(output_max)])\n",
    "weight_name = \"weights/CSE_test/{}-{}.png\".format(input_file_name.split('.')[0], label_key[int(output_max)])\n",
    "#########################################\n",
    "\n",
    "np_img = np.array(image)[:, :, ::-1]\n",
    "mask = cv2.resize(mask, (np_img.shape[1], np_img.shape[0]))\n",
    "mask_ = show_mask_on_image(np_img, mask)\n",
    "\n",
    "np_img_ = np.zeros(np_img.shape)\n",
    "for t in range(np_img.shape[2]):\n",
    "    np_img_[:,:,t] = np_img[:,:,t] * mask\n",
    "\n",
    "input_ = Image.fromarray(np.uint8(np_img_))\n",
    "input_ = test_transforms(input_).unsqueeze(0)\n",
    "input_ = input_.to(device)\n",
    "output_ = model(input_)\n",
    "output_max_ = result(label_key, output_, 'weight')\n",
    "output_max_ = draw(label_key, output_, 'weight')\n",
    "\n",
    "cv2.imwrite('../input.png', np_img);\n",
    "cv2.imwrite('../heatmap.png', mask * 255);\n",
    "cv2.imwrite(heatmap_name, mask * 255);\n",
    "cv2.imwrite('../output.png', mask_);\n",
    "cv2.imwrite(output_name, mask_);\n",
    "cv2.imwrite('../weight.png', np_img_);\n",
    "cv2.imwrite(weight_name, np_img_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db547acdbe0d8c01ab0f92785cee0c5ffdcae5ee11abcdf1f9927c721543542e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
